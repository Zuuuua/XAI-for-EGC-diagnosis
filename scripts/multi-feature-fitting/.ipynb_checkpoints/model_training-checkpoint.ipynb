{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T01:30:53.343043Z",
     "start_time": "2022-07-26T01:30:52.269859Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "from itertools import combinations,permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T01:30:57.207508Z",
     "start_time": "2022-07-26T01:30:56.892896Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ori_csv_path = \"拟合.xlsx\"\n",
    "ai_csv_path = ori_csv_path\n",
    "df = pd.read_excel(ori_csv_path)\n",
    "df_ai = pd.read_excel(ai_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T01:30:58.806285Z",
     "start_time": "2022-07-26T01:30:58.781351Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Tone'] = df['Tone'].astype(str)\n",
    "df_ai['Tone'] = df_ai['Tone'].astype(str)\n",
    "df['Location'] = df['Location'].astype(str)\n",
    "df_ai['Location'] = df_ai['Location'].astype(str)\n",
    "mid = pd.get_dummies(df[df.columns[3:]])\n",
    "head = df[df.columns[:3]]\n",
    "mid_ai = pd.get_dummies(df_ai[df_ai.columns[3:]])\n",
    "head_ai = df_ai[df_ai.columns[:3]]\n",
    "new_df = pd.concat([head,mid],axis=1)\n",
    "new_df_ai = pd.concat([head_ai,mid_ai],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T01:31:00.650930Z",
     "start_time": "2022-07-26T01:31:00.637965Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.columns,len(new_df.columns)\n",
    "issmic_train_features = new_df.loc[new_df['Training/Testing'] == 'Training'].iloc[:,3:].values\n",
    "issmic_train_labels = new_df.loc[new_df['Training/Testing'] == 'Training'].iloc[:,2].values\n",
    "issmic_train_features.shape, issmic_train_labels.shape\n",
    "time.strftime('%m-%d',time.localtime())\n",
    "result_name = '{}_{}features_{}trained'.format(time.strftime('%m-%d',time.localtime()),issmic_train_features.shape[1],issmic_train_features.shape[0])\n",
    "result_path = os.path.join(\"model\",result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T07:39:23.115832Z",
     "start_time": "2023-06-08T07:39:23.097880Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "issmic_test_features = new_df_ai.loc[new_df_ai['Training/Testing'] == 'Testing'].iloc[:,3:].values\n",
    "issmic_test_labels = new_df_ai.loc[new_df_ai['Training/Testing'] == 'Testing'].iloc[:,2].values\n",
    "issmic_test_features.shape, issmic_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T01:31:08.990537Z",
     "start_time": "2022-07-26T01:31:08.974556Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(train_x, train_y):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    model = MultinomialNB(alpha=0.01)  \n",
    "    model.fit(train_x, train_y,verbose=1)  \n",
    "    return model\n",
    "\n",
    "def gaussian_classifier(train_x, train_y):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    model = GaussianNB()  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model\n",
    "def knn_classifier(train_x, train_y):  \n",
    "    from sklearn.neighbors import KNeighborsClassifier  \n",
    "    model = KNeighborsClassifier()  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "def logistic_regression_classifier(train_x, train_y):  \n",
    "    from sklearn.linear_model import LogisticRegression  \n",
    "    model = LogisticRegression(penalty='l2',solver='lbfgs', max_iter=100)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "def random_forest_classifier(train_x, train_y):  \n",
    "    from sklearn.ensemble import RandomForestClassifier  \n",
    "    model = RandomForestClassifier(n_estimators=8,random_state=66)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "def decision_tree_classifier(train_x, train_y):  \n",
    "    from sklearn import tree  \n",
    "    model = tree.DecisionTreeClassifier()  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "def gradient_boosting_classifier(train_x, train_y):  \n",
    "    from sklearn.ensemble import GradientBoostingClassifier  \n",
    "    model = GradientBoostingClassifier(n_estimators=200)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "def svm_classifier(train_x, train_y):  \n",
    "    from sklearn.svm import SVC  \n",
    "    model = SVC(kernel='rbf', probability=True)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  \n",
    "def svm_cross_validation(train_x, train_y):  \n",
    "    from sklearn.model_selection import GridSearchCV  \n",
    "    from sklearn.svm import SVC  \n",
    "    model = SVC(kernel='rbf', probability=True)  \n",
    "    param_grid = {'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}  \n",
    "    grid_search = GridSearchCV(model, param_grid, n_jobs = 1, verbose=1)  \n",
    "    grid_search.fit(train_x, train_y)  \n",
    "    best_parameters = grid_search.best_estimator_.get_params()  \n",
    "    for para, val in list(best_parameters.items()):  \n",
    "        print(para, val)  \n",
    "    model = SVC(kernel='rbf', C=best_parameters['C'], gamma=best_parameters['gamma'], probability=True)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T07:39:11.621980Z",
     "start_time": "2023-06-08T07:39:11.611010Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_csv(columns, data, csv_path, index=False, header=True):\n",
    "    data_array = np.array(data)\n",
    "    df = pd.DataFrame(data_array.T, columns=columns)\n",
    "    df.to_csv(csv_path, encoding='gbk', index=index, header=header) \n",
    "test_classifiers = ['GNB','KNN', 'LR', 'RF', 'DT', 'SVM', 'GBDT']\n",
    "classifiers = {'NB':naive_bayes_classifier,  \n",
    "               'GNB':gaussian_classifier,\n",
    "              'KNN':knn_classifier,  \n",
    "               'LR':logistic_regression_classifier,  \n",
    "               'RF':random_forest_classifier,  \n",
    "               'DT':decision_tree_classifier,  \n",
    "              'SVM':svm_classifier,  \n",
    "            'SVMCV':svm_cross_validation,  \n",
    "             'GBDT':gradient_boosting_classifier  \n",
    "}  \n",
    "train_xs = [issmic_train_features]\n",
    "train_ys = [issmic_train_labels]\n",
    "test_xs = [issmic_test_features]\n",
    "test_ys = [issmic_test_labels]\n",
    "cases = ['neoplasm_diagnosis']\n",
    "ori_csv_name = os.path.split(ori_csv_path)[-1]\n",
    "ori_csv_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T01:31:12.017773Z",
     "start_time": "2022-07-26T01:31:11.966824Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(os.path.join(result_path,ori_csv_name[:-4]+'_processed'+  '.csv'),index=False,encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T07:38:55.223045Z",
     "start_time": "2023-06-08T07:38:55.204061Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for case_idx in range(len(cases)):\n",
    "    \n",
    "    features_choose_list = []\n",
    "    \n",
    "    NB_acc_list = []\n",
    "    NB_train_acc_list = []\n",
    "    NB_avg_acc_list = []\n",
    "    NB_sens_list = []\n",
    "    NB_spec_list = []\n",
    "    \n",
    "    GNB_acc_list = []\n",
    "    GNB_avg_acc_list = []\n",
    "\n",
    "    KNN_acc_list = []\n",
    "    KNN_avg_acc_list = []\n",
    "\n",
    "    LR_acc_list = []\n",
    "    LR_avg_acc_list = []\n",
    "\n",
    "    RF_acc_list = []\n",
    "    RF_avg_acc_list = []\n",
    "\n",
    "    DT_acc_list = []\n",
    "    DT_avg_acc_list = []\n",
    "\n",
    "    SVM_acc_list = []\n",
    "    SVM_avg_acc_list = []\n",
    "\n",
    "    GBDT_acc_list = []\n",
    "    GBDT_avg_acc_list = []\n",
    "\n",
    "    acc_dict = { \n",
    "        'NB':NB_acc_list,\n",
    "        'GNB':GNB_acc_list,\n",
    "        'KNN':KNN_acc_list,  \n",
    "        'LR':LR_acc_list,  \n",
    "        'RF':RF_acc_list,  \n",
    "        'DT':DT_acc_list,  \n",
    "        'SVM':SVM_acc_list,   \n",
    "        'GBDT':GBDT_acc_list  \n",
    "    }  \n",
    "    \n",
    "    avg_acc_dict = { \n",
    "        'NB':NB_avg_acc_list,\n",
    "        'GNB':GNB_avg_acc_list,\n",
    "        'KNN':KNN_avg_acc_list,  \n",
    "        'LR':LR_avg_acc_list,  \n",
    "        'RF':RF_avg_acc_list,  \n",
    "        'DT':DT_avg_acc_list,  \n",
    "        'SVM':SVM_avg_acc_list,   \n",
    "        'GBDT':GBDT_avg_acc_list  \n",
    "    }  \n",
    "\n",
    "    acc_max = 0\n",
    "    train_acc_max = 0\n",
    "    avg_acc_max = 0\n",
    "    featrues_len = issmic_train_features.shape[1]  \n",
    "    _train_x=train_xs[case_idx]\n",
    "    _train_y=train_ys[case_idx]\n",
    "    _test_x=test_xs[case_idx]\n",
    "    _test_y=test_ys[case_idx]\n",
    "    \n",
    "    featrues_idxs=list(range(featrues_len))\n",
    "    csv_name = cases[case_idx] + '.csv'\n",
    "\n",
    "    min_combination_num = 2\n",
    "    for num in tqdm(range(min_combination_num,featrues_len+1)):   \n",
    "        choose_idxs = list(combinations(featrues_idxs,num))\n",
    "        for choose_idx in choose_idxs:\n",
    "            train_x = _train_x[:, choose_idx]\n",
    "            train_y = _train_y\n",
    "            test_x = _test_x[:, choose_idx]\n",
    "            test_y = _test_y\n",
    "            choose_features = ','.join([str(x) for x in choose_idx])\n",
    "            features_choose_list.append(choose_features)\n",
    "            for classifier in test_classifiers:  \n",
    "                start_time = time.time()  \n",
    "                model = classifiers[classifier](train_x, train_y)  \n",
    "                predict = model.predict(test_x)   \n",
    "                c = confusion_matrix(test_y, predict)\n",
    "                acc = (c[0][0] + c[1][1]) / (np.sum(c)) * 100\n",
    "                train_pred = model.predict(train_x)\n",
    "                train_c = confusion_matrix(train_y, train_pred)\n",
    "                \n",
    "                train_acc = (train_c[0][0] + train_c[1][1]) / (np.sum(train_c)) * 100\n",
    "                avg_acc = (train_acc + acc)/2.\n",
    "                \n",
    "                if acc > acc_max:\n",
    "                    features_acc_max = choose_features\n",
    "                    methods_acc_max = classifier\n",
    "                    acc_max = acc\n",
    "                    \n",
    "                if train_acc > train_acc_max:\n",
    "                    features_train_acc_max = choose_features\n",
    "                    methods_train_acc_max = classifier\n",
    "                    train_acc_max = train_acc\n",
    "                    \n",
    "                if avg_acc > avg_acc_max:\n",
    "                    features_avg_acc_max = choose_features\n",
    "                    methods_avg_acc_max = classifier\n",
    "                    avg_acc_max = avg_acc\n",
    "    \n",
    "                acc_dict[classifier].append(\"{:.2f}%\".format(acc))\n",
    "                avg_acc_dict[classifier].append(\"{:.2f}%\".format(avg_acc))\n",
    "    print(\"{},best_acc, {},{},{}\".format(cases[case_idx], features_acc_max, methods_acc_max, acc_max)) \n",
    "    print(\"{},best_avg_acc, {},{},{}\".format(cases[case_idx], features_avg_acc_max, methods_avg_acc_max, avg_acc_max)) \n",
    "    columns = ['features', 'GNB_acc', 'GNB_avg_acc','KNN_acc','KNN_avg_acc',  'LR_acc','LR_avg_acc','RF_acc', 'RF_avg_acc',\n",
    "              'DT_acc', 'DT_avg_acc','SVM_acc', 'SVM_avg_acc','GBDT_acc','GBDT_avg_acc']\n",
    "    data = [features_choose_list, GNB_acc_list, GNB_avg_acc_list, KNN_acc_list,KNN_avg_acc_list, LR_acc_list, LR_avg_acc_list,\n",
    "            RF_acc_list,RF_avg_acc_list, DT_acc_list, DT_avg_acc_list,SVM_acc_list, SVM_avg_acc_list, GBDT_acc_list, GBDT_avg_acc_list]\n",
    "    csv_path = os.path.join(result_path, csv_name)\n",
    "    save_csv(columns, data, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
